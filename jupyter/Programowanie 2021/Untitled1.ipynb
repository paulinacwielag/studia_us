{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d37a1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6499b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "488159cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/users/paulina.cwielag/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instalowanie konkretnego pakietu\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e06bd",
   "metadata": {},
   "source": [
    "## Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "099e4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy ='''Picture yourself in a boat on a river\n",
    "With tangerine trees and marmalade skies\n",
    "Somebody calls you, you answer quite slowly\n",
    "A girl with kaleidoscope eyes\n",
    "Cellophane flowers of yellow and green\n",
    "Towering over your head\n",
    "Look for the girl with the sun in her eyes\n",
    "And she's gone'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0347718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z kropkami\n",
    "lucy = '''Picture yourself in a boat on a river. \n",
    "With tangerine trees and marmalade skies. \n",
    "Somebody calls you, you answer quite slowly. \n",
    "A girl with kaleidoscope eyes. \n",
    "Cellophane flowers of yellow and green. \n",
    "Towering over your head. \n",
    "Look for the girl with the sun in her eyes. \n",
    "And she's gone.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27bb5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b44bd4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ala', 'ma', 'kota']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('Ala ma kota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b273aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Picture', 'yourself', 'in', 'a', 'boat', 'on', 'a', 'river', '.', 'With', 'tangerine', 'trees', 'and', 'marmalade', 'skies', '.', 'Somebody', 'calls', 'you', ',', 'you', 'answer', 'quite', 'slowly', '.', 'A', 'girl', 'with', 'kaleidoscope', 'eyes', '.', 'Cellophane', 'flowers', 'of', 'yellow', 'and', 'green', '.', 'Towering', 'over', 'your', 'head', '.', 'Look', 'for', 'the', 'girl', 'with', 'the', 'sun', 'in', 'her', 'eyes', '.', 'And', 'she', \"'s\", 'gone', '.']\n"
     ]
    }
   ],
   "source": [
    "words = (word_tokenize(lucy))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f13dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dbed253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ala ma kota.', 'Ala ma psa.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize('Ala ma kota. Ala ma psa.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc0d32cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Picture yourself in a boat on a river.',\n",
       " 'With tangerine trees and marmalade skies.',\n",
       " 'Somebody calls you, you answer quite slowly.',\n",
       " 'A girl with kaleidoscope eyes.',\n",
       " 'Cellophane flowers of yellow and green.',\n",
       " 'Towering over your head.',\n",
       " 'Look for the girl with the sun in her eyes.',\n",
       " \"And she's gone.\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(lucy) # tokenizacja ze względu na zdania, z kropkami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "082b1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"she's\" -> 'she is' / 'she has'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ce3e4",
   "metadata": {},
   "source": [
    "## Wstępne przetwarzanie tekstu\n",
    "### (a) stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65cfe7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/users/paulina.cwielag/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f9f70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # nie działa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d12db790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e7c21",
   "metadata": {},
   "source": [
    "## Ćwiczenie 1\n",
    "Usuń stopwords z tekstu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dbc48895",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "\n",
    "filtered_lucy = []\n",
    "for word in words:\n",
    "    if word not in stopw:\n",
    "        filtered_lucy.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "452414aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Picture', 'boat', 'river', '.', 'With', 'tangerine', 'trees', 'marmalade', 'skies', '.', 'Somebody', 'calls', ',', 'answer', 'quite', 'slowly', '.', 'A', 'girl', 'kaleidoscope', 'eyes', '.', 'Cellophane', 'flowers', 'yellow', 'green', '.', 'Towering', 'head', '.', 'Look', 'girl', 'sun', 'eyes', '.', 'And', \"'s\", 'gone', '.']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_lucy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06648b56",
   "metadata": {},
   "source": [
    "## Ćwiczenie 2\n",
    "Usuń znaki przestankowe z przefiltrowanej listy filtered_lucy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3238025b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "88f5e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Picture', 'boat', 'river', 'With', 'tangerine', 'trees', 'marmalade', 'skies', 'Somebody', 'calls', 'answer', 'quite', 'slowly', 'A', 'girl', 'kaleidoscope', 'eyes', 'Cellophane', 'flowers', 'yellow', 'green', 'Towering', 'head', 'Look', 'girl', 'sun', 'eyes', 'And', \"'s\", 'gone']\n"
     ]
    }
   ],
   "source": [
    "better_lucy = []\n",
    "\n",
    "for word in filtered_lucy:\n",
    "    if word not in punctuation:\n",
    "        better_lucy.append(word)\n",
    "print(better_lucy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4f3d4",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "19c2898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter\n",
    "from nltk.stem import PorterStemmer # klasyfikacja wyrazów i tematów\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b2cf855d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "321ace7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect\n",
      "connect\n",
      "connect\n",
      "connect\n",
      "connect\n"
     ]
    }
   ],
   "source": [
    "lista = ['connection', 'connections', 'connective', 'connected', 'connecting']\n",
    "\n",
    "for el in lista:\n",
    "    print(stemmer.stem(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "77a6d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "# snowball\n",
    "from nltk.stem import SnowballStemmer # klasyfikacja dla różnych języków\n",
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7685a",
   "metadata": {},
   "source": [
    "## Lemmatyzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "24b17aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33916d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in connect: # jakiś tekst\n",
    "    print(\"temat {} to {}\".format(c, wordnet_lemmatizer.lemmatize(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2d426e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/users/paulina.cwielag/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temat: Picture to Picture, stem: pictur\n",
      "Temat: yourself to yourself, stem: yourself\n",
      "Temat: in to in, stem: in\n",
      "Temat: a to a, stem: a\n",
      "Temat: boat to boat, stem: boat\n",
      "Temat: on to on, stem: on\n",
      "Temat: a to a, stem: a\n",
      "Temat: river to river, stem: river\n",
      "Temat: . to ., stem: .\n",
      "Temat: With to With, stem: with\n",
      "Temat: tangerine to tangerine, stem: tangerin\n",
      "Temat: trees to tree, stem: tree\n",
      "Temat: and to and, stem: and\n",
      "Temat: marmalade to marmalade, stem: marmalad\n",
      "Temat: skies to sky, stem: sky\n",
      "Temat: . to ., stem: .\n",
      "Temat: Somebody to Somebody, stem: somebodi\n",
      "Temat: calls to call, stem: call\n",
      "Temat: you to you, stem: you\n",
      "Temat: , to ,, stem: ,\n",
      "Temat: you to you, stem: you\n",
      "Temat: answer to answer, stem: answer\n",
      "Temat: quite to quite, stem: quit\n",
      "Temat: slowly to slowly, stem: slowli\n",
      "Temat: . to ., stem: .\n",
      "Temat: A to A, stem: a\n",
      "Temat: girl to girl, stem: girl\n",
      "Temat: with to with, stem: with\n",
      "Temat: kaleidoscope to kaleidoscope, stem: kaleidoscop\n",
      "Temat: eyes to eye, stem: eye\n",
      "Temat: . to ., stem: .\n",
      "Temat: Cellophane to Cellophane, stem: cellophan\n",
      "Temat: flowers to flower, stem: flower\n",
      "Temat: of to of, stem: of\n",
      "Temat: yellow to yellow, stem: yellow\n",
      "Temat: and to and, stem: and\n",
      "Temat: green to green, stem: green\n",
      "Temat: . to ., stem: .\n",
      "Temat: Towering to Towering, stem: tower\n",
      "Temat: over to over, stem: over\n",
      "Temat: your to your, stem: your\n",
      "Temat: head to head, stem: head\n",
      "Temat: . to ., stem: .\n",
      "Temat: Look to Look, stem: look\n",
      "Temat: for to for, stem: for\n",
      "Temat: the to the, stem: the\n",
      "Temat: girl to girl, stem: girl\n",
      "Temat: with to with, stem: with\n",
      "Temat: the to the, stem: the\n",
      "Temat: sun to sun, stem: sun\n",
      "Temat: in to in, stem: in\n",
      "Temat: her to her, stem: her\n",
      "Temat: eyes to eye, stem: eye\n",
      "Temat: . to ., stem: .\n",
      "Temat: And to And, stem: and\n",
      "Temat: she to she, stem: she\n",
      "Temat: 's to 's, stem: 's\n",
      "Temat: gone to gone, stem: gone\n",
      "Temat: . to ., stem: .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "''''With tangerine trees and marmalade skies\n",
    "Somebody calls you, you answer quite slowly\n",
    "A girl with kaleidoscope eyes\n",
    "Cellophane flowers of yellow and green\n",
    "Towering over your head\n",
    "Look for the girl with the sun in her eyes\n",
    "And she's gone'''\n",
    "\n",
    "for w in word_tokenize(lucy):\n",
    "    print('Temat: {} to {}, stem: {}'.format(w, wordnet_lemmatizer.lemmatize(w), stemmer.stem(w))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26b4a9",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f2d10ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "71d88462",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/home/users/paulina.cwielag/nltk_data'\n    - '/opt/miniconda3/nltk_data'\n    - '/opt/miniconda3/share/nltk_data'\n    - '/opt/miniconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2638499/504643676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetter_lucy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'universal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             AP_MODEL_LOC = \"file:\" + str(\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"taggers/averaged_perceptron_tagger/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             )\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/home/users/paulina.cwielag/nltk_data'\n    - '/opt/miniconda3/nltk_data'\n    - '/opt/miniconda3/share/nltk_data'\n    - '/opt/miniconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "pos_tag(better_lucy, tagset = 'universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e02c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
